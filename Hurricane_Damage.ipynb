{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Hurricane-Damage.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gC2-7gGpmxYj"
      },
      "source": [
        "# Importing Data and Libs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "62qLiXi_ljQD"
      },
      "source": [
        "#Pip installs\n",
        "!pip install kaggle\n",
        "\n",
        "#Import\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "\n",
        "import tensorflow as tf\n",
        "import keras_preprocessing\n",
        "from keras_preprocessing import image\n",
        "from keras_preprocessing.image import ImageDataGenerator\n",
        "\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import Model\n",
        "from tensorflow.keras.optimizers import RMSprop\n",
        "\n",
        "import glob\n",
        "import imageio\n",
        "import numpy as np\n",
        "import PIL\n",
        "import time\n",
        "import pathlib\n",
        "from IPython import display\n",
        "\n",
        "from zipfile import ZipFile\n",
        "from google.colab import files"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HA_nirvNn4mz"
      },
      "source": [
        "#Kaggle Data Import\n",
        "files.upload()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "etwHInPAn70M"
      },
      "source": [
        "!mkdir -p ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle/\n",
        "\n",
        "!chmod 600 ~/.kaggle/kaggle.json"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J_WddSqgn9p1"
      },
      "source": [
        "!kaggle datasets download --force -d kmader/satellite-images-of-hurricane-damage\n",
        "\n",
        "file_name = \"/content/satellite-images-of-hurricane-damage.zip\"\n",
        "\n",
        "with ZipFile(file_name, 'r') as zip:\n",
        "  zip.extractall()\n",
        "  print('done')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4CSIfjgWddwZ"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QAdTJQnYlQmm"
      },
      "source": [
        "#Formatting Data and Visualizing "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ajS4jJ02lZr_"
      },
      "source": [
        "!rm -rf '/content/test_another'\n",
        "!rm -rf '/content/validation_another'\n",
        "\n",
        "train_no_damage_dir = os.path.join('/content/train_another/no_damage')\n",
        "train_damage_dir = os.path.join('/content/train_another/damage')\n",
        "test_no_damage_dir = os.path.join('/content/test/no_damage')\n",
        "test_damage_dir = os.path.join('/content/test/damage')\n",
        "\n",
        "print('total training damage images:', len(os.listdir(train_damage_dir)))\n",
        "print('total training no damage images:', len(os.listdir(train_no_damage_dir)))\n",
        "print('total testing damage images:', len(os.listdir(test_damage_dir)))\n",
        "print('total testing no damage images:', len(os.listdir(test_no_damage_dir)))\n",
        "\n",
        "damage_files = os.listdir(train_damage_dir)\n",
        "print(damage_files[:10])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F13AXWbk_qUg"
      },
      "source": [
        "%matplotlib inline\n",
        "pic_index = 2\n",
        "next_img = [os.path.join(train_damage_dir, fname) \n",
        "                for fname in damage_files[pic_index-2:pic_index]]\n",
        "\n",
        "for i, img_path in enumerate(next_img):\n",
        "  print(img_path)\n",
        "  img = mpimg.imread(img_path)\n",
        "  plt.imshow(img)\n",
        "  plt.axis('Off')\n",
        "  plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X6t0oae3Aun9"
      },
      "source": [
        "train_datagen = ImageDataGenerator(\n",
        "      rescale=1./255,\n",
        "      rotation_range=40,\n",
        "      width_shift_range=0.2,\n",
        "      height_shift_range=0.2,\n",
        "      shear_range=0.2,\n",
        "      zoom_range=0.2,\n",
        "      horizontal_flip=True,\n",
        "      vertical_flip=True,\n",
        "      fill_mode='nearest')\n",
        "\n",
        "validation_datagen = ImageDataGenerator(rescale=1/255)\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "        '/content/train_another/',  \n",
        "        target_size=(300, 300), \n",
        "        batch_size=128,\n",
        "        class_mode='binary')\n",
        "\n",
        "validation_generator = validation_datagen.flow_from_directory(\n",
        "        '/content/test/',  \n",
        "        target_size=(300, 300),  \n",
        "        batch_size=128,\n",
        "        class_mode='binary')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hAqsN5YDBcvW"
      },
      "source": [
        "#Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JBCOj_TmBclX"
      },
      "source": [
        "model = tf.keras.models.Sequential([\n",
        "    tf.keras.layers.Conv2D(32, (3,3), activation='relu', input_shape=(300, 300, 3)),\n",
        "    tf.keras.layers.MaxPooling2D(2, 2),\n",
        "    tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(2,2),\n",
        "    tf.keras.layers.Conv2D(128, (3,3), activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(2,2),\n",
        "    tf.keras.layers.Conv2D(128, (3,3), activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(2,2),\n",
        "    tf.keras.layers.Dropout(0.5),\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dense(512, activation='relu'),\n",
        "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ons6z50XB2C8"
      },
      "source": [
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "model.compile(optimizer = Adam(lr=0.0001), \n",
        "              loss = 'binary_crossentropy', \n",
        "              metrics = ['accuracy'])\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xNAhX2LhBxEl"
      },
      "source": [
        "from keras.callbacks import EarlyStopping\n",
        "\n",
        "EPOCHS = 10\n",
        "es = EarlyStopping(\n",
        "    monitor='val_loss', \n",
        "    mode='min',\n",
        "    patience=10\n",
        ")\n",
        "\n",
        "history = model.fit(\n",
        "  train_generator,\n",
        "  steps_per_epoch=int(10000/128),  \n",
        "  epochs=EPOCHS,\n",
        "  validation_data = validation_generator,\n",
        "  validation_steps=int(2000/128),\n",
        "  callbacks=[es]\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7PrXZwLRLzmH"
      },
      "source": [
        "model.save(\"hurricane-weights.h5\")\n",
        "\n",
        "# Plotting Accuracy\n",
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs = range(len(acc))\n",
        "\n",
        "plt.plot(epochs, acc, 'r', label='Training accuracy')\n",
        "plt.plot(epochs, val_acc, 'b', label='Validation accuracy')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.legend(loc=0)\n",
        "plt.figure()\n",
        "\n",
        "plt.show()\n",
        "\n",
        "plt.plot(epochs, loss, 'r', label='Training loss')\n",
        "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.legend(loc=0)\n",
        "plt.figure()\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "84qEAIMNPBXc"
      },
      "source": [
        "loss, acc = model.evaluate(validation_generator, verbose=2)\n",
        "print(\"Loss of model: \" + str(loss))\n",
        "print(\"Accuracy of model: \"+ str(acc*100))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}